# MySQL 基础架构

## 1 MySQL 逻辑架构图
![MySQL 逻辑架构图](https://github.com/wxdyhj/awesome-mysql/blob/master/png/mysql_structure.png)

### 1.1 连接器
* 连接器负责跟客户端建立连接、获取权限、维持和管理连接
* 成功建立连接后，即使用管理员账号修改该用户的权限，也不会影响已存在的连接；修改后的权限只对新建的连接生效
* 通过 ```show processlist``` 命令可查看当前 MySQL 不同连接的处理状态
```
mysql> show processlist;
+----+------+-----------------+------+---------+------+-------+------------------+
| Id | User | Host            | db   | Command | Time | State | Info             |
+----+------+-----------------+------+---------+------+-------+------------------+
|  1 | root | localhost:49795 | test | Sleep   |   49 |       | NULL             |
|  2 | root | localhost:49796 | NULL | Sleep   |    9 |       | NULL             |
|  4 | root | localhost:56162 | NULL | Query   |    0 | NULL  | show processlist |
+----+------+-----------------+------+---------+------+-------+------------------+s
```
* 如果客户端长时间没有操作，连接器会自动断开当前连接，由参数 wait_timeout 控制，默认 8 小时，查看 wait_timeout 值的命令如下，查询结果的单位是秒
```
mysql> show global variables like 'wait_timeout';
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| wait_timeout  | 28800 |
+---------------+-------+
```
* 在连接被 MySQL 服务端断开后，如果客户端在发送请求，就会收到一个错误提醒：Lost connection to MySQL server during query
* 数据库长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接；短连接是指每次执行完很少的几个请求就断开连接，下次查询再重新创建连接
* 创建连接的过程通常是比较复杂的，建议尽量减少创建连接的动作，也就是尽量使用长连接
* MySQL 在执行过程中临时使用的内存是管理在连接对象里，这些资源会在连接断开时才释放。所以如果长连接累计到一定量，可能导致 MySQL 内存占用太大，发生 OOM，现象就是 MySQL 异常重启了
* 解决内存占用过大的两种方案：
    * 定期断开长连接：定时或者由程序拍短，执行一个内存占用较大的查询后，断开连接，之后使用时再建立连接
    * 如果 MySQL 版本是 5.7 或者更新，可以在每次执行一个较大的操作后，通过执行 ```mysql_reset_connect``` 命令来重新初始化连接资源，该过程不会重连和鉴权，但是会将连接恢复到刚刚创建完的状态

### 1.2 查询缓存
* 建立连接后，就可以执行 select 等语句，此时执行逻辑会来到第二：查询缓存。
* 之前执行过的语句及其结果可能会以键值对（key-value pairs）的形式缓存在内存中，key 是查询语句，value 是查询的结果
* 如果查询能在缓存中找到对应的 key，就会将 key 对应的 value 直接返回客户端
* 如果语句不在查询缓存中，就会继续后面的执行阶段，执行完成后，执行结果会被存入查询缓存中
* 大多数情况下，不建议使用查询缓存，因为缓存往往弊大于利
* 查询缓存很容易失效，只要对一个表执行更新操作，这个表上的所有查询缓存都会被清空。除非是静态表，很长时间才会更新一次，比如系统配置表的查询才适合使用查询缓存
* MySQL 提供按需使用的方式，通过将参数 query_cache_type 设置为 DEMAND，默认的 sql 语句都不使用查询缓存，对于要使用查询环迅的语句，可以用 SQL_CACHE 显示指定
```
select SQL_CACHE * from table_name where id = 1;
```
* 注意：从 MySQL 8.0 版本开始，不再支持查询缓存的功能

### 1.3 分析器
* 如果没有命中查询缓存，就要开始真正执行语句。经过分析器，MySQL 就知道要做什么了。以如下 sql 语句为例进行分析
```
select * from T where id = 1;
```
* 分析器首先会做“词法分析”，sql 语句由多个自古穿和空格组成，MySQL 需要识别出里面的字符串分别是什么，分别代表什么
* MySQL 从 select 关键字识别出这是一个查询语句，它也要把字符串 “T” 识别成“表名 T”，把字符串 “id” 识别成 “列 id”
* 做完上述识别后，就要做“语法分析”，根据语法分析的结果，语法分析器会根据语法规则，判断 sql 语句是否满足 MySQL 语法
* 如果语法不对，就会收到“You have an error in your SQL syntax” 的错误提醒
* 举例如下，故意将 select 写成 elect
```
mysql> elect SQL_CACHE * from student where id = 1;
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'elect SQL_CACHE * from student where id = 1' at line 1
```

### 1.4 优化器
分析器的主要工作：当一张表有多个索引时，决定使用哪个索引；或者再一个语句由多表关联（join）时，决定各个表的连接顺序

举例说明：
```
 select * from t1 join t2 using(id) where t1.c=10 and t2.d=20;
```
查表时，有以下两种方案：
* 方案 1：先从 t1 表取出 c = 10 的记录的 id 的值，再根据 id 值关联到 t2 表，再判断 t2 表里面 d 的值是否等于 20
* 方案 2：先从 t2 表里取出 d = 20 的记录的 id 的值，再根据 id 值关联到 t1 表，再判断 t1 表里面的 c 的值是否等于 10

这两种方案的逻辑结果是一样的，但是执行的效率会有所不同，优化器的作用就是决定选择使用哪种方案

### 1.5 执行器
Mysql 通过分析器知道要做什么，通过优化器知道该怎么做，于是进入执行器阶段，开始执行语句。

开始执行时，先判断对这个表是否有执行查询的权限，如果没有就会返回没有权限的错误；如果有权限，就打开表继续执行，打开表时执行器就会根据表的引擎定义，去使用对应引擎提供的接口

## 2 一条 SQL 查询语句是如何执行的
* InnoDB 引擎支持 OLTP
* OLTP 是 OnLine Transaction Processing 的缩写，中文译为联机事务处理，表示事务性非常高的系统，一般是高可用的在线系统，以小的事务以及小的查询系统。典型的 OLTP 系统有：电子商务系统、银行、证券等

以 ``` select * from T where id = 10;``` 为例进行分析，假设表的 id 字段没有索引，则执行器的执行流程如下：
* 调用 InnoDB 引擎接口，取 T 表的第一行，判断 id 的值是否等于 10，如果不是则跳过，如果是则将这行数据存在结果集中
* 调用引擎接口取“下一行”数据，重复相同的判断逻辑，直到取到这个表的最后一行
* 执行器将上述遍历流程中所有满足条件的行组成的记录集作为结果集返回给客户端

## 3 一条 SQL 更新语句是如何执行的
假设表 T 的建表语句为```create table T(id int primary key, c int);```，则表 T 包含一个逐渐 id 和一个整型字段 c；如果要将 id = 2 这一行的 c 字段的值加 1，sql 语句为 ```update T set c = c + 1 where id = 2;```。查询语句的执行流程，更新语句也会走一遍
执行流程大致如下：
* 连接数据库
* 在一张表上游更新操作时，跟这个表相关的查询缓存就会失效，所以该更新语句会清空表 T 上的缓存结果，这也是一般不建议使用查询缓存的原因
* 分析器通过此法和语法分析知道这是一条更新语句，优化器决定使用 id 这个索引
* 执行器负责具体执行，找到 id = 2 的这一行数据，然后更新
* 与查询流程不一样的是，更新流程还设计两个重要的日志模块，redo log（重做日志）和 binlog（归档日志）

### 3.1 redo log
* redo log 是 InnoDB 引擎特有的日志模块
* 如果每次更新操作都要写进磁盘，先找到磁盘中对应的记录，再执行更新，整个过程 IO 成本、查找成本都很高，MySQL 使用了 WAL（Write Ahead Logging）技术来提升更新效率，也就是先写日志，再写磁盘
* 举例：更新一条记录时，InnoDB 引擎先把记录写到 redo log 中，并更新内存，这时候更新就算完成了，InnoBD 引擎会在适当的时机将这个记录更新到磁盘中
* InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小为 1GB，那么总共可以记录 4GB 的操作，从头开始写，写到末尾又回到开头循环写
* InnoDB 的 redo log可以保证即使数据库发生异常重启，之前提交的记录也不会丢失，这个能力成为 crash safe

### 3.2 binlog
* server 层也有自己的日志，称为 binlog（归档日志）
* binlog 有两种模式：statement 格式记得是 sql 语句，row 格式记得是行的内容，会记录两条，更新前和更新后的
* 为什么要有 2 份日志：刚开始 MySQL 没有 InnoDB 引擎，MySQL 自带的引擎时 MyISAM，但是 MyISAM 没有 crash safe 的能力，binlog 日志只能用于归档，而 InnoDB 是另一家公司以插件形式引入 MySQL 的，由于 binlog 不具备 crash safe 能力，所以 InnoDB 使用 redo log 来实现 crash safe

redo log 和 binlog 的区别
* redo log 是 InnoDB 引擎特有的；binlog 是 MySQL server 层实现的，所有引擎都可以使用
* redo log 是物理日志，记录的是“在某个数据页做了哪些修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 id = 2 这一行的 c 字段加 1”
* redo log 是循环写的，空间固定会用完；binlog 是追加写入；“追加写”是指 binlog 文件写到一定大小后会切换到下一个，而不会覆盖以前的日志

执行器和 InnoDB 引擎在执行 update 语句的内部流程：
* 执行器先找到引擎 id = 2 的这一行，id 是主键，引擎直接用树搜索找到这一行。如果 id = 2 这一行所在的数据页本来就在内存中，就会直接返回给执行器；否则需要先从磁盘读入内存，再返回
* 执行器拿到引擎给的行数据，把 c 的值加1，得到新的一行数据，再调用引擎接口写入这行新数据
* 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于准备（prepare）状态。然后告知执行器执行完了，随时可以提交事务
* 执行器生成这个操作的 binlog，并把 binlog 写入磁盘
* 执行器调用引擎提交事务的接口，引擎把刚写入的 redo log 改成提交（commit）状态，更新完成

### 3.3 二阶段提交
两阶段提交协议，2PC，Two-Phase Commit Protocol

MySQL 采用二阶段事务提交协议，当操作完成后，首先 Prepare 事务，在 binlog 中实际上只是 fake 一下，不作任何事情，而 innodb 层需要将 prepare 写入 redo log 中；然后执行 commit 事务，首先在 binlog 中写入操作日志，完成后在 Innodb 的 redo log 中写入 commit 日志。

MySQL 二阶段提交的步骤：
1. 写 redo log，进入 prepare 阶段
2. 写 binlog
3. redo log 进入 commit 阶段，完成

分以下情况分析：
* 假设在步骤 1 过程中崩溃，显然当前更新不生效；
* 假设在步骤 2 之前崩溃，重启后根据 redo log 的 crash safe 功能，发现日志未 commit，所以回滚处于 prepare 状态的日志
* 假设在步骤 2 和 步骤 3 之间崩溃，重启恢复：虽然没有 commit，但是 redo log 处于 prepare 且 binlog 完整，所以重启后会自动 commits

假设有表被误删，则数据恢复过程：找到最近的一次全量备份，从备份的时间点开始，将备份的 binlog 依次取出重放到误删表之前的那个时刻，这样得到的临时库就跟误删之前的线上库一样了，之后再将临时库的数据按需恢复到线上库即可。

### 3.4 小结
binlog 的重要参数
* sync_binlog：用于控制何时将 binlog 写入磁盘
    * 参数为 0 时，并不是立即写入磁盘，而是依赖操作系统的 fsync 机制
    * 参数为 1 时，表示每次事务的 binlog 都持久化到磁盘，保证 MySQL 异常重启后 binlog 不丢
    * 参数大于 1 时，表示达到指定提交次数后，统一 fsync 到磁盘
* innodb_flush_log_at_trx_commit：参数设为 1，表示每次事务的 redo log 都直接持久化到磁盘，保证 MySQL 异常重启之后不丢数据

## 4 事务
### 4.1 基础知识
#### 4.1.1 事务的概念
MySQL 事务是一个或者过个数据库操作，要么全部执行成功，要么全部失败回滚。事务是通过事务日志来实现的，事务日志包括：redo log 和 undo log

#### 4.1.2 事务的特性
ACID
* 原子性（Atomicity，又称不可分割性）：事务的数据操作，要么全部执行成功，要么全部失败回滚到执行事务之前的状态，就像这个事务从来没执行过一样
* 一致性（Consistency）：在事务操作前后，数据都是保持一个相同的状态，数据库的完整性没有被破坏。原子性和隔离性对一致性有至关重要的影响
* 隔离性（Isolation）：多个事务之间是互相隔离，互不影响的。数据库允许多个并发事务同事对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致
* 持久性（Durability）：当事务操作完成后，数据会被刷新到磁盘永久保存，即便系统故障也不会丢失

#### 4.1.3 事务的状态
* 活动（active）：事务对应的数据库操作正在执行
* 部分提交（partially commited）：当十五中的最后一个操作执行完成，但由于操作都在内存中执行，锁造成的影响并没有刷新到磁盘时，称该事务处于部分提交的状态
* 失败（failed）：处于活动或者部分提交状态的事务，可能遇到某些错误（数据库自身的操作、操作系统错误或者直接断电等）而无法继续执行，或者认为停止当前事务，称该事务处于失败状态
* 中止（aborted）：撤销失败事务对当前数据库造成的影响的过程，称为回滚。当回滚操作执行完毕时，也就是数据库恢复到了执行事务之前的状态，该事务处就处于中止状态
* 提交（commited）：处于部分提交状态的事务，将修改过的数据同步到磁盘上之后，该事务就处于提交状态

![事务不同状态间的转换](https://github.com/wxdyhj/awesome-mysql/blob/master/png/state_of_transaction.png)

#### 4.1.4 事务的启动方式
```
mysql> begin;
// 执行各种操作
mysql> commit; // 或者 rollback;
```

### 4.2 事务隔离
#### 4.2.1 事务隔离级别
当数据库上有多个事务同事执行时，就可能出现脏读（dirty read）、不可重复度（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念，隔离越严，效率越低，标准被事务隔离级别包括：
* **读未提交**（read uncommitted）：一个事务还没提交时，它做的变更就能被别的事务看到
* **读已提交**（read committed）：一个事务提交之后，它做的变更才会被其他事务看到
* **可重复度**（repeatable read）：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据一致，在该隔离级别下，未提交的变更对其他事务不可见
* **串行化**（serializable）：对于同一行记录，写操作会加写锁，读操作会加读锁。当出现读写锁冲突时，后访问的事务必须等前一个事务执行完成才能继续执行

快速理解脏读、不可重复读和幻读：
* 脏读：可能发生在读未提交的隔离级别。事务 A 读取事务 B 尚提交的数据，如果事务 B 发生错误并执行回滚操作，那么事务 A 读取到的数据就是脏数据
* 不可重复读：可能发生在读未提交和读已提交的隔离级别。指的是前后多次读取的数据内容不一致。事务 A 在执行读取操作，事务 B 执行更改操作，这可能导致事务 A 多次读取的数据不一致
* 幻读：可能发生在读未提交、读已提交、可重复读的隔离级别。指的是前后多次读取，得到的数据总量不一致。事务 A 在执行读取操作，需要两次统计数据的总量，第一次查询数据总量后，事务 B 执行了新增数据的操作并且已提交，事务 A 第二次读取的数据总量就和之前统计的不一致，就像产生了幻觉一样，称为幻读

不可重复读和幻读的区别：
* 不可重复读是读取了其他事务更改的数据，针对的是 update 操作。解决方案：使用行级锁，锁定该行，事务 A 多次读取操作完成后才释放改锁
* 幻读是读取了其他事务新增的数据，针对 insert 和 delete 操作。解决方案：使用表级锁，锁定整张表，事务 A 多次读取数据总量之后才释放锁

举个例子解释不同隔离级：
```
create table T(c int) engine=InnoDB;
```
从上到下，按时间顺序执行事务 A 和事务 B：

![mysql 并行事务示例](https://github.com/wxdyhj/awesome-mysql/blob/master/png/mysql_transaction.png)

不同隔离级别下，事务 A 查询得到的 v1, v2, v3 的值
* 读未提交：虽然事务 B 还没提交，但是结果已对事务 A 可见，所以 v1 的值为 2，显然 v2 和 v3 的值也都为 2
* 读已提交：事务 B 还没提交，所以 v1 的值是 1，v2 和 v3 是在事务 B 提交之后读取，所以值为 2
* 可重复度：因为事务 A 在执行过程中看到的值都一样，所以 v1 和 v2 的值都为 1，v3 为 2
* 串行化：事务 B 在执行“将 1 改为 2” 时会加写锁，由于事务 A 比事务 B 先启动，所以需要等事务 A 提交后，事务 B 才能获得写锁，才能继续执行，所以从事务 A 的角度来看，v1 和 v2 都是 1，v3 为 2

这四种隔离方式从上到下的性能依次降低，但安全性依次升高

查看 MySQL 的隔离级别：```show variables like '%tx_isolation%';```

在实现上，数据库会创建一个视图，访问时以视图的逻辑结果为准。可重复读在事务启动时创建视图，整个事务存在期间都用这个视图；读已提交在每个SQL语句开始执行时创建视图。读未提交直接返回记录上的最新值，没有视图概念；而串行化直接用加锁的方式来避免并行访问。

#### 4.2.2 事务隔离的实现
展开说明“可重复读”。

在 MySQL 中，每条记录在更新时都会同时记录一条回滚操作，记录最新值，通过回滚操作都可以得到上一个状态的值，假设一个值从 1 按顺序被改成 2、3、4，那么在回滚日志里就会有类似下面的记录：

![回滚记录](https://github.com/wxdyhj/awesome-mysql/blob/master/png/mysql_rollback.png)

当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。

尽量不要使用长事务。原因：长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会大量占用存储空间。

在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。

## 5 Q&A
* question 1: 如果 T 表中没有 k 字段，```select * from T where k = 1```，肯定会报“列不存在”的错误，这个错误会发生在哪个阶段？
* answer 1: 分析器。（不是执行器的原因：执行器会打开表获取表数据，但是表的字段不是数据，是实现定义好的，所以可以直接读取而不需要打开表）
* question 2: 为什么日志需要两阶段提交？
* answer 2: 由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么先写 redo log 再写 binlog，或者先写 binlog 再写 redo log。以 sql ```update T set c = c + 1 where id = 2;``` 为例进行分析，假设 c 字段的值为 0，再假设执行 update 过程中，再写完第一个日志后，第二个日志还没写完就发生 crash，分析可能出现的情况：
    * 先写 redo log 再写 binlog：假设写完 redo log，binlog 还没写完，MySQL 进程异常重启；由于 redo log 具备 crash safe 的能力，所以即使系统崩溃，也能恢复数据，所以恢复后 c 的值变为 1，但由于 binlog 还没洗完就 crash 了，这时候 binlog 里没有记录这条语句，如果需要使用 binlog 来恢复临时库，恢复出的 c 的值就是 0，与原库的值不同。
    * 先写 binlog 再写 redo log：如果 binlog 写完之后 crash，由于 redo log 还没写，update 在崩溃恢复后无效，所以 id 等于 2 的这行记录的 c 的值为 0，但是 binlog 里面已经记录“把 c 从 0 改为 1”的日志，所以之后使用 binlog 恢复的数据，这一行记录的 c 的值为 1，与原库的值不同。

由此可见，如果不使用“两阶段提交”，数据库的状态就可能和用它的日志恢复出来的状态不一致。
